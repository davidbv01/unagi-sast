import OpenAI from 'openai';
import { z } from 'zod';
import { zodTextFormat } from 'openai/helpers/zod';
import { DataFlowCodeExtraction } from './CodeExtractor';

export const VulnerabilityAnalysisSchema = z.object({
  isVulnerable: z.boolean(),                    
  confidenceScore: z.number().min(0).max(1),         
  shortExplanation: z.string(),                 
  exploitExample: z.string(),        
  remediation: z.string()  
});

export type VulnerabilityAnalysis = z.infer<typeof VulnerabilityAnalysisSchema>;

export interface VerificationRequest {
  codeExtraction: DataFlowCodeExtraction;
  initialVulnerabilityAssessment: {
    type: string;
    severity: string;
    message: string;
    description?: string;
  };
  context?: {
    language: string;
    framework?: string;
    additionalInfo?: string;
  };
}

export class VulnerabilityVerifier {
  private openai: OpenAI;
  private model: string;

  constructor(apiKey: string, model: string = 'gpt-4o-mini-2024-07-18') {
    this.openai = new OpenAI({
      apiKey: apiKey,
    });
    this.model = model;
  }

  public async verifyVulnerability(request: VerificationRequest): Promise<VulnerabilityAnalysis> {
    const prompt = this.buildPrompt(request);
    const response = await this.openai.responses.parse({
      model: this.model,
      input: [
        { role: 'system', content: this.getSystemPrompt() },
        { role: 'user', content: prompt },
      ],
      text: {
        format: zodTextFormat(VulnerabilityAnalysisSchema, 'vulnerability'),
      },
    });
    if (!response.output_parsed) {
      throw new Error('LLM did not return a valid vulnerability analysis result.');
    }
    return response.output_parsed;
  }

  private buildPrompt(request: VerificationRequest): string {
    const { codeExtraction, initialVulnerabilityAssessment, context } = request;
    let prompt = `Analyze the following code for security vulnerabilities. The initial static analysis detected a potential ${initialVulnerabilityAssessment.type} vulnerability with ${initialVulnerabilityAssessment.severity} severity.\n\n`;

    prompt += `## Initial Assessment\n- Type: ${initialVulnerabilityAssessment.type}\n- Severity: ${initialVulnerabilityAssessment.severity}\n- Message: ${initialVulnerabilityAssessment.message}\n`;
    if (initialVulnerabilityAssessment.description) {
      prompt += `- Description: ${initialVulnerabilityAssessment.description}\n`;
    }

    if (context?.language) {
      prompt += `\n## Context\n- Language: ${context.language}\n`;
      if (context.framework) prompt += `- Framework: ${context.framework}\n`;
      if (context.additionalInfo) prompt += `- Additional Info: ${context.additionalInfo}\n`;
    }

    if (codeExtraction.sourceFunction) {
      prompt += `### Source Function\nFunction: ${codeExtraction.sourceFunction.functionName}\nLines: ${codeExtraction.sourceFunction.startLine}-${codeExtraction.sourceFunction.endLine}\n\`\`\`${codeExtraction.sourceFunction.language || 'python'}\n${codeExtraction.sourceFunction.sourceCode}\n\`\`\`\n\n`;
    }

    if (codeExtraction.sinkFunction) {
      prompt += `### Sink Function\nFunction: ${codeExtraction.sinkFunction.functionName}\nLines: ${codeExtraction.sinkFunction.startLine}-${codeExtraction.sinkFunction.endLine}\n\`\`\`${codeExtraction.sinkFunction.language || 'python'}\n${codeExtraction.sinkFunction.sourceCode}\n\`\`\`\n\n`;
    }

    if (codeExtraction.sanitizerFunctions.length > 0) {
      prompt += `### Sanitizer Functions\n`;
      codeExtraction.sanitizerFunctions.forEach((sanitizer, index) => {
        prompt += `#### Sanitizer ${index + 1}: ${sanitizer.functionName}\nLines: ${sanitizer.startLine}-${sanitizer.endLine}\n\`\`\`${sanitizer.language || 'python'}\n${sanitizer.sourceCode}\n\`\`\`\n\n`;
      });
    }

    // Clean and ensure fullContext code is always shown correctly
    const fullCode = codeExtraction.fullContext?.trim() || '[No code found]';
    prompt += `### Full Context\n\`\`\`${context?.language || 'python'}\n${fullCode}\n\`\`\`\n\n`;

    prompt += `## Instructions\nPlease provide a thorough security analysis of this code, focusing on:\n1. Whether the initial vulnerability assessment is accurate\n2. The actual exploitability of any vulnerabilities found\n3. The effectiveness of any sanitization measures\n4. The likelihood of false positives\n5. Specific attack vectors and remediation recommendations\n\nConsider the data flow from source to sink and evaluate if untrusted data can reach sensitive operations without proper validation or sanitization.`;

    console.log(prompt);
    return prompt;
  }


  private getSystemPrompt(): string {
    return `You are a senior security researcher and code auditor specializing in vulnerability analysis. Your task is to verify potential security vulnerabilities identified by static analysis tools.\n\nYou should:\n1. Carefully analyze the provided code for genuine security vulnerabilities\n2. Assess the exploitability and real-world impact of any issues found\n3. Evaluate the effectiveness of existing sanitization measures\n4. Identify false positives and explain why they occur\n5. Provide actionable security recommendations\n\nBe thorough, accurate, and practical in your analysis. Consider modern security best practices and common vulnerability patterns. Pay special attention to data flow from untrusted sources to sensitive sinks.\n\nYour response must be a valid JSON object following the specified schema exactly.`;
  }
} 