import OpenAI from 'openai';    
import { zodTextFormat } from 'openai/helpers/zod';
import { VulnerabilityAnalysis, VulnerabilityAnalysisSchema, VerificationRequest } from '../types';

/**
 * Verifies vulnerabilities using an LLM (OpenAI) and structured prompts.
 */
export class VulnerabilityVerifier {
  private readonly openai: OpenAI;
  private readonly model: string;

  /**
   * Creates a new VulnerabilityVerifier instance.
   * @param apiKey The OpenAI API key.
   * @param model The LLM model to use (default: gpt-4.1-mini-2025-04-14).
   */
  constructor(apiKey: string, model: string = 'gpt-4.1-mini-2025-04-14') {
    this.openai = new OpenAI({
      apiKey: apiKey,
    });
    this.model = model;
  }
  
  /**
   * Verifies multiple vulnerabilities using the LLM with shared context.
   * @param vulnerabilities Array of vulnerabilities to verify.
   * @param codeExtraction The code extraction string containing context for all vulnerabilities.
   * @param context The analysis context.
   * @returns Array of vulnerability analysis results.
   */
  public async verifyVulnerabilities(
    vulnerabilities: Array<{
      type: string;
      severity: string;
      message: string;
      description?: string;
      line?: number;
      id: string;
    }>,
    codeExtraction: string,
    context?: {
      language: string;
      framework?: string;
      additionalInfo?: string;
    }
  ): Promise<VulnerabilityAnalysis[]> {
    console.log('[VulnerabilityVerifier] Processing multiple vulnerabilities with shared context');
    
    // For now, we'll verify each vulnerability individually but with shared context
    // This could be enhanced to use a single LLM call with multiple outputs
    const results: VulnerabilityAnalysis[] = [];
    
    for (const vuln of vulnerabilities) {
      console.log(`[VulnerabilityVerifier] Verifying vulnerability ${vuln.id}: ${vuln.type}`);
      console.log('[VulnerabilityVerifier] Prompt:', codeExtraction);
      
      const response = await this.openai.responses.parse({
        model: this.model,
        input: [
          { role: 'system', content: this.getSystemPrompt() },
          { role: 'user', content: codeExtraction },
        ],
        text: {
          format: zodTextFormat(VulnerabilityAnalysisSchema, 'vulnerability'),
        },
      });
      
      if (!response.output_parsed) {
        throw new Error(`LLM did not return a valid vulnerability analysis result for vulnerability ${vuln.id}.`);
      }
      
      results.push(response.output_parsed);
    }
    
    return results;
  }

  /**
   * Returns the system prompt for the LLM.
   * @returns The system prompt string.
   */
  private getSystemPrompt(): string {
    return `You are a senior security researcher. Analyze the provided code for actual security vulnerabilities. Assess exploitability, real-world impact, and sanitization quality. Flag false positives with clear reasons. Provide actionable, specific security recommendations. Your answer must be a valid JSON object matching the given schema exactly.`;
  }
} 